# ROS-LLaMA Project

This is a **ROS 1** project using `llama-cpp-python` with **LLaMA 3.2 Q8** for text parsing and command extraction.

Instead of using **Gemma 3**, we switched to **LLaMA 3.2** due to better inference time performance.

---

## ðŸ§  Overview

The system processes natural language instructions and transforms them into executable robotic commands. For example:

> **Input**: "Pick the glass and place it on the kitchen table."  
> **Output**: `["pick", "glass", "place", "kitchen_table"]`

---

## ðŸ“¦ ROS Nodes

There are **3 nodes** in this system:

| Node            | Script           | Description                                                  |
|-----------------|------------------|--------------------------------------------------------------|
| `ros-llama.py`  | Runs the LLaMA model | Subscribes to input topic and publishes parsed command list |
| `publisher.py`  | Publishes input text | Gets user input and publishes it to the input topic         |
| `subscriber.py` | Subscribes to output | Receives parsed command array and logs/displays it          |

These scripts are located in the `./llama-python/scripts` directory.

---

## ðŸ“ Directory Structure

```
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ llama-python
â”‚   â”œâ”€â”€ catkin_ws
â”‚   â”œâ”€â”€ json/
â”‚   â”‚   â”œâ”€â”€ en/
â”‚   â”‚   â”‚   â”œâ”€â”€ actions_100.json
â”‚   â”‚   â”‚   â”œâ”€â”€ actions.json
â”‚   â”‚   â”‚   â”œâ”€â”€ examples.json
â”‚   â”‚   â”‚   â”œâ”€â”€ objects_100.json
â”‚   â”‚   â”‚   â””â”€â”€ objects.json
â”‚   â”‚   â””â”€â”€ ro/
â”‚   â”‚       â”œâ”€â”€ actiuni.json
â”‚   â”‚       â”œâ”€â”€ exemple.json
â”‚   â”‚       â””â”€â”€ obiecte.json
â”‚   â”œâ”€â”€ llama.py              # Starter script (non-ROS)
â”‚   â”œâ”€â”€ models/               # GGUF models (not uploaded to GitHub)
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ publisher.py
â”‚       â”œâ”€â”€ ros-llama.py
â”‚       â””â”€â”€ subscriber.py
â”œâ”€â”€ README.md
â”œâ”€â”€ start.sh
â””â”€â”€ terminals.sh
```

---

## âš™ï¸ Framework

We use [`llama-cpp-python`](https://pypi.org/project/llama-cpp-python/0.1.9/) with OpenMP and BLAS support for optimized CPU execution.

---

## ðŸ§© Models Tested

```
models/
â”œâ”€â”€ gemma3/
â”‚   â”œâ”€â”€ bartowski/     [1]
â”‚   â”‚   â”œâ”€â”€ google_gemma-3-12b-it-IQ2_M.gguf
â”‚   â”‚   â””â”€â”€ google_gemma-3-12b-it-Q4_K_M.gguf
â”‚   â””â”€â”€ unsloth/       [2]
â”‚       â”œâ”€â”€ gemma-3-12b-it-UD-IQ2_M.gguf
â”‚       â””â”€â”€ gemma-3-12b-it-Q4_K_M.gguf
â””â”€â”€ llama3.2/
    â”œâ”€â”€ bartowski/     [3]
    â”‚   â”œâ”€â”€ Llama-3.2-3B-Instruct-Q4_K_M.gguf
    â”‚   â””â”€â”€ Llama-3.2-3B-Instruct-Q6_K_L.gguf
    â””â”€â”€ unsloth/       [4]
        â”œâ”€â”€ Llama-3.2-3B-Instruct-Q2_K.gguf
        â”œâ”€â”€ Llama-3.2-3B-Instruct-Q3_K_S.gguf
        â”œâ”€â”€ Llama-3.2-3B-Instruct-Q4_K_M.gguf
        â””â”€â”€ Llama-3.2-3B-Instruct-Q8_0.gguf
```

---

## ðŸš€ Getting Started

### âš ï¸ Optional Cleanup

To remove all Docker containers/images:

```bash
sudo docker stop $(sudo docker ps -aq)
sudo docker rm $(sudo docker ps -aq)
sudo docker rmi $(sudo docker images -q)
```

---

### ðŸ”§ Start Docker + ROS Master

```bash
./start.sh
```

- This builds and starts the Docker container (`ros_llama_container`)
- Mounts `./llama-python` to `/root`
- Sets up the ROS workspace and installs scripts as ROS nodes

---

### ðŸ–¥ï¸ Launch ROS Nodes

```bash
sudo ./terminals.sh
```

This script opens 3 new GNOME terminal windows:

- One for each node (`ros-llama.py`, `publisher.py`, `subscriber.py`)
- Each terminal stays open and lets you interact with the scripts
- Run with `sudo` to avoid entering your password for each terminal

> âš ï¸ Do not modify any Python scripts under `catkin_ws/`. They are auto-copied from `./llama-python/scripts/`.

---

## ðŸ”„ ROS Workflow

```text
[ publisher.py ]  -->  /llama_parser/input   --> [ ros-llama.py ] --> /llama_parser/commands --> [ subscriber.py ]
```

1. `publisher.py` takes user input and publishes to `/llama_parser/input`
2. `ros-llama.py` parses the text using LLaMA and publishes the command list
3. `subscriber.py` logs the parsed command list received from `/llama_parser/commands`

---

## ðŸ”— References

1. [Bartowski's Gemma 3 GGUF](https://huggingface.co/bartowski/google_gemma-3-12b-it-GGUF)
2. [Unsloth Gemma 3 GGUF](https://huggingface.co/unsloth/gemma-3-12b-it-GGUF)
3. [Bartowski LLaMA 3.2 GGUF](https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF)
4. [Unsloth LLaMA 3.2 GGUF](https://huggingface.co/unsloth/Llama-3.2-3B-Instruct-GGUF)
5. [llama-cpp-python v0.1.9](https://pypi.org/project/llama-cpp-python/0.1.9/)

---
